# ai </br>
Проект посвещен AI </br>
Тут выкладываю статьи по установке и расмотрим все плюсы и минусы моделей AI</br></br>


<table border="1">
    <tr>
        <th>Модель</th>
        <th>Параметры</th>
        <th>Плюсы</th>
        <th>Минусы</th>
        <th>Генерация изображений</th>
        <th>Генерация видео</th>
        <th>Написание кода</th>
        <th>Требуется API</th>
        <th>Работает без интернета</th>
    </tr>
    <tr>
        <td>GPT-4</td>
        <td>1.76 трлн параметров</td>
        <td>Высокая точность, поддержка нескольких языков, хорошая логика</td>
        <td>Высокие требования к ресурсам, платный доступ</td>
        <td>Нет</td>
        <td>Нет</td>
        <td>Да</td>
        <td>Да</td>
        <td>Нет</td>
    </tr>
    <tr>
        <td>GPT-3.5</td>
        <td>175 млрд параметров</td>
        <td>Быстрее и дешевле GPT-4, хороший баланс качества</td>
        <td>Хуже логика и генерация кода по сравнению с GPT-4</td>
        <td>Нет</td>
        <td>Нет</td>
        <td>Да</td>
        <td>Да</td>
        <td>Нет</td>
    </tr>
    <tr>
        <td>Mistral 7B</td>
        <td>7 млрд параметров</td>
        <td>Быстрая, бесплатная, хорошо оптимизирована</td>
        <td>Уступает GPT-4 в качестве генерации</td>
        <td>Нет</td>
        <td>Нет</td>
        <td>Да</td>
        <td>Нет</td>
        <td>Да</td>
    </tr>
    <tr>
        <td>Mixtral 8x7B</td>
        <td>Модель MoE (56 млрд параметров, 2 активных слоя)</td>
        <td>Высокая скорость работы, точность, низкие требования к ресурсам</td>
        <td>Может давать менее креативные ответы</td>
        <td>Нет</td>
        <td>Нет</td>
        <td>Да</td>
        <td>Нет</td>
        <td>Да</td>
    </tr>
    <tr>
        <td>LLaMA 2 13B</td>
        <td>13 млрд параметров</td>
        <td>Баланс между качеством и производительностью</td>
        <td>Требует больше памяти, чем Mistral 7B</td>
        <td>Нет</td>
        <td>Нет</td>
        <td>Да</td>
        <td>Нет</td>
        <td>Да</td>
    </tr>
    <tr>
        <td>LLaMA 2 65B</td>
        <td>65 млрд параметров</td>
        <td>Отличное качество генерации текста</td>
        <td>Очень высокие требования к оборудованию</td>
        <td>Нет</td>
        <td>Нет</td>
        <td>Да</td>
        <td>Нет</td>
        <td>Да</td>
    </tr>
    <tr>
        <td>Falcon 40B</td>
        <td>40 млрд параметров</td>
        <td>Оптимизирован для скорости и точности</td>
        <td>Трудно запустить на слабом оборудовании</td>
        <td>Нет</td>
        <td>Нет</td>
        <td>Да</td>
        <td>Нет</td>
        <td>Да</td>
    </tr>
    <tr>
        <td>Falcon 180B</td>
        <td>180 млрд параметров</td>
        <td>Высокая точность, мощный генеративный потенциал</td>
        <td>Огромные требования к ресурсам</td>
        <td>Нет</td>
        <td>Нет</td>
        <td>Да</td>
        <td>Нет</td>
        <td>Нет</td>
    </tr>
    <tr>
        <td>Claude 3 Opus</td>
        <td>Не раскрыто</td>
        <td>Лучше GPT-4 в некоторых задачах, особенно по контексту</td>
        <td>Платный, доступ ограничен</td>
        <td>Нет</td>
        <td>Нет</td>
        <td>Да</td>
        <td>Да</td>
        <td>Нет</td>
    </tr>
    <tr>
        <td>Gemini 1.5 Pro</td>
        <td>Не раскрыто</td>
        <td>Отличная мультимодальность, работа с длинным контекстом</td>
        <td>Некоторые ограничения в генерации текста</td>
        <td>Да</td>
        <td>Да</td>
        <td>Да</td>
        <td>Да</td>
        <td>Нет</td>
    </tr>
    <tr>
        <td>Gemini 1.5 Ultra</td>
        <td>Не раскрыто</td>
        <td>Самая мощная версия Gemini, лучшая работа с длинным контекстом</td>
        <td>Высокая цена, доступ ограничен</td>
        <td>Да</td>
        <td>Да</td>
        <td>Да</td>
        <td>Да</td>
        <td>Нет</td>
    </tr>
</table>
